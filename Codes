#Importing the Libraries
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Define paths
base_dir = r'C:\Users\risha\OneDrive\Desktop\Assignment\AI 2\archive (7)\chest_xray\chest_xray'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
--------------------------------------------------------------------------------------
# Data Augmentation and Rescaling
train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
val_datagen = ImageDataGenerator(rescale=1./255)
--------------------------------------------------------------------------------------
# Create the generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)
----------------------------------------------------------------------------------------------------------------
from tensorflow.keras import layers, models

# Define the model
model = models.Sequential()
# Use Input layer to define input shape
model.add(layers.Input(shape=(150, 150, 3)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification
-----------------------------------------------------------------------------------------------
import numpy as np
from sklearn.utils import class_weight
from keras.callbacks import EarlyStopping, ModelCheckpoint

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define class weights
classes = [0, 1]  # Adjust as necessary
y_train = np.concatenate([train_generator[i][1] for i in range(len(train_generator))])  # Get y_train
class_weights = compute_class_weight('balanced', classes=classes, y=y_train)
class_weight_dict = dict(enumerate(class_weights))

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True)  # Change to .keras
callbacks = [early_stopping, model_checkpoint]
-----------------------------------------------------------------------------
# Check the shape of data from the generators
x_batch, y_batch = next(train_generator)
print("x_batch shape:", x_batch.shape)
print("y_batch shape:", y_batch.shape)

# Also check for validation data
x_val_batch, y_val_batch = next(val_generator)
print("x_val_batch shape:", x_val_batch.shape)
print("y_val_batch shape:", y_val_batch.shape)
-----------------------------------------------------------------------------------------------------------------------
# Training the model without class weights and callbacks for testing
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    epochs=30,
    validation_data=val_generator,
    validation_steps=val_generator.samples // 32
)
-------------------------------------------------------------------------------------------------------------------
# Evaluate the model on the validation set
val_loss, val_accuracy = model.evaluate(val_generator)

# Convert accuracy to percentage
val_accuracy_percentage = val_accuracy * 100

print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy_percentage:.2f}%")
--------------------------------------------------------------------------------------------------------
import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')

plt.tight_layout()
plt.show()
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
